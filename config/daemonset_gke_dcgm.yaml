apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: custom-dcgm-exporter
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: custom-gke-dcgm-exporter
  template:
    metadata:
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
      labels:
        app.kubernetes.io/name: custom-gke-dcgm-exporter
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: cloud.google.com/gke-accelerator
                operator: Exists
              - key: cloud.google.com/gke-gpu-driver-version
                operator: In
                values:
                - default
                - latest
      automountServiceAccountToken: false
      containers:
      - args:
        - --enable-dcgm-log
        - --dcgm-log-level
        - ERROR
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
        - name: DCGM_EXPORTER_KUBERNETES_GPU_ID_TYPE
          value: device-name
        - name: DCGM_EXPORTER_KUBERNETES
          value: "true"
        - name: DCGM_EXPORTER_LISTEN
          value: :9400
        #image: us-west2-artifactregistry.gcr.io/gke-release/gke-release/nvidia/gke-dcgm-exporter:3.3.9-3.6.1-gke.11@sha256:80dae82c957920007dc29b8478355217b3c8c22d54fb8297e8000ed64af74c3b
        image: gcr.io/gke-release/nvidia/gke-dcgm-exporter:4.2.3-4.1.3-gke.6
        imagePullPolicy: IfNotPresent
        name: dcgm-exporter
        ports:
        - containerPort: 9400
          name: metrics
          protocol: TCP
        resources:
          limits:
            memory: 350Mi
          requests:
            cpu: 100m
            memory: 350Mi
        securityContext:
          privileged: true
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /etc/dcgm-exporter
          name: dcgm-exporter-metrics
          readOnly: true
        - mountPath: /usr/local/nvidia
          name: nvidia-install-dir-host
          readOnly: true
        - mountPath: /var/lib/kubelet/pod-resources
          name: pod-resources
          readOnly: true
      initContainers:
      - command:
        - /bin/bash
        - -c
        - |
          cleanup() {
            echo "caught stop signal, exiting..."
            exit 0
          }
          trap cleanup SIGINT SIGTERM
          echo "checking for drivers"
          while true; do
            if ls "/usr/local/nvidia/lib64/libnvidia-ml.so.1" &>/dev/null; then
              echo "nvml drivers found!"
              break
            fi
            echo "waiting for nvml drivers"
            sleep 1
          done
          echo "checking for MIG partitions"
          if [[ -f "/etc/nvidia/gpu_config.json" ]]; then
            content=$(</etc/nvidia/gpu_config.json)
            if [[ -z "${content##*GPUPartitionSize*}" ]]; then
              while true; do
                output=$(LD_LIBRARY_PATH=/usr/local/nvidia/lib64 /usr/local/nvidia/bin/nvidia-smi -L)
                echo $output
                if [[ -z "${output##*MIG*MIG-*}" ]]; then
                  echo "MIG partitions found, exiting"
                  break
                fi
                echo "waiting for MIG partitions"
                sleep 2
              done
            else
              echo "GPUPartitionSize is empty"
            fi
          else
            echo "no gpu config"
          fi
          echo "checking for gpu-device-plugin socket"
          while true; do
            if [[ $(ls /var/lib/kubelet/device-plugins/nvidiaGPU*.sock) ]]; then
              ls -la /var/lib/kubelet/device-plugins/nvidiaGPU*.sock
              echo "gpu-device-plugin socket found, exiting"
              exit 0
            fi
            echo "waiting for gpu-device-plugin socket"
            sleep 1
          done
        image: us-west2-artifactregistry.gcr.io/gke-release/gke-release/gke-distroless/bash:gke_distroless_20250321.00_p0@sha256:7f776c36ecf7426b9d461b2b9690ff6b6c7fc1d00c78eb050da3e039d431b760
        imagePullPolicy: IfNotPresent
        name: nvml-wait
        securityContext:
          privileged: true
          readOnlyRootFilesystem: true
        volumeMounts:
        - mountPath: /usr/local/nvidia
          name: nvidia-install-dir-host
          readOnly: true
        - mountPath: /etc/nvidia
          name: nvidia-config
          readOnly: true
        - mountPath: /var/lib/kubelet/device-plugins
          name: device-plugins
          readOnly: true
      priorityClassName: system-node-critical
      restartPolicy: Always
      tolerations:
      - operator: Exists
      - key: components.gke.io/gke-managed-components
        operator: Exists
      volumes:
      - hostPath:
          path: /home/kubernetes/bin/nvidia
          type: Directory
        name: nvidia-install-dir-host
      - configMap:
          defaultMode: 420
          name: custom-dcgm-exporter-metrics
        name: dcgm-exporter-metrics
      - hostPath:
          path: /var/lib/kubelet/pod-resources
          type: Directory
        name: pod-resources
      - hostPath:
          path: /var/lib/kubelet/device-plugins
          type: Directory
        name: device-plugins
      - hostPath:
          path: /etc/nvidia
          type: DirectoryOrCreate
        name: nvidia-config
  updateStrategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
---
apiVersion: v1
data:
  default-counters.csv: |-
    ## GPU performance metrics,,
    # FieldID 100
    DCGM_FI_DEV_SM_CLOCK, gauge, SM clock frequency (in MHz).
    # FieldID 140
    DCGM_FI_DEV_MEMORY_TEMP, gauge, Memory temperature for the device.
    # FieldID 150
    DCGM_FI_DEV_GPU_TEMP, gauge, Current temperature readings for the device in degrees C.
    # FieldID 155
    DCGM_FI_DEV_POWER_USAGE, gauge, Power usage for the device in Watts.
    # Field ID 156
    DCGM_FI_DEV_TOTAL_ENERGY_CONSUMPTION, counter, Total energy consumption for the GPU in mJ since the driver was last reloaded.

    # Utilization (the sample period varies depending on the product),,
    # FieldID 203
    DCGM_FI_DEV_GPU_UTIL, gauge, GPU utilization (in %).
    # FieldID 204
    DCGM_FI_DEV_MEM_COPY_UTIL, gauge, Memory utilization (in %).

    # Memory usage,,
    # FieldID 250
    DCGM_FI_DEV_FB_TOTAL, gauge, Total Frame Buffer of the GPU in MB.
    # FieldID 251
    DCGM_FI_DEV_FB_FREE, gauge, Framebuffer memory free (in MiB).
    # FieldID 252
    DCGM_FI_DEV_FB_USED, gauge, Framebuffer memory used (in MiB).

    # Profiling metrics,,
    # FieldID 1001
    DCGM_FI_PROF_GR_ENGINE_ACTIVE, gauge, Ratio of time the graphics engine is active.
    # FieldID 1002
    DCGM_FI_PROF_SM_ACTIVE, gauge, The ratio of cycles an SM has at least 1 warp assigned.
    # FieldID 1004
    DCGM_FI_PROF_PIPE_TENSOR_ACTIVE, gauge, The ratio of cycles the tensor (HMMA) pipe is active (off the peak sustained elapsed cycles).
    # FieldID 1005
    DCGM_FI_PROF_DRAM_ACTIVE, gauge, Ratio of cycles the device memory interface is active sending or receiving data.
    # FieldID 1006
    DCGM_FI_PROF_PIPE_FP64_ACTIVE, gauge, The fraction of cycles the FP64 (double precision) pipe was active.
    # FieldID 1007
    DCGM_FI_PROF_PIPE_FP32_ACTIVE, gauge, The fraction of cycles the FP32 (single precision) pipe was active.
    # FieldID 1008
    DCGM_FI_PROF_PIPE_FP16_ACTIVE, gauge, The fraction of cycles the FP16 (half precision) pipe was active.

    # PCIE,,
    # FieldID 1009
    DCGM_FI_PROF_PCIE_TX_BYTES, gauge, Total number of bytes transmitted through PCIe TX.
    # FieldID 1010
    DCGM_FI_PROF_PCIE_RX_BYTES, gauge, Total number of bytes received through PCIe RX.

    # NVLink,,
    # FieldID 1011
    DCGM_FI_PROF_NVLINK_TX_BYTES, gauge, The number of bytes of active NvLink tx (transmit) data including both header and payload.
    # FieldID 1012
    DCGM_FI_PROF_NVLINK_RX_BYTES, gauge, The number of bytes of active NvLink rx (read) data including both header and payload.
kind: ConfigMap
metadata:
  name: custom-dcgm-exporter-metrics
---
apiVersion: monitoring.googleapis.com/v1
kind: ClusterPodMonitoring
metadata:
  name: custom-gke-dcgm-exporter
spec:
  endpoints:
  - interval: 30s
    port: metrics
  selector:
    matchLabels:
      app.kubernetes.io/name: custom-gke-dcgm-exporter
  targetLabels:
    metadata: []
